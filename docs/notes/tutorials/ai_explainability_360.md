# AI Explainability 360

| Item | Description |
| --- | --- | 
| FAT Reference | [AI Explainability 360 Tutorial](https://fatconference.org/2020/acceptedtuts.html#ai) |
| Paper | [AI explainability 360: hands-on tutorial](https://dl.acm.org/doi/abs/10.1145/3351095.3375667) |
| Microsite | [AI Explainability 360 Tutorial](https://github.com/IBM/AIX360/wiki/ACM-FAT*2020-Tutorial) |


## Notes

### General Interpretability Metrics

- Maximum mean discrepancy critic
- Saliency maps
    - Image explainability
    - Aims to highlight the objects that determined the classification
    - Works by identifying how much the classification changes based on different components in the image
- Knowledge Distilation

### AI 360 Intro

- Developed by IBM
- Developed a taxonomy that can be explored to identify the most appropriate technique
    - (add photo/slide of the taxonomy)
- Types:
    - *post-hoc*: explain each point/observation etc
    - *self-explaining*: The model to derive the explanations might not be explainable


### Example

**Use-case**: *whether or not a financial institute should offer a loan to a loan applicant*

The demo is available online but behind a login.